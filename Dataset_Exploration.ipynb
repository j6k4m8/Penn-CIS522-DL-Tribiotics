{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j6k4m8/CIS522-DL-Tribiotics/blob/main/Dataset_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zm5yjT0f8of"
      },
      "source": [
        "## CIS 522 Final Project - DL Interpretability in COVID X-ray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip0UvSGTedRy"
      },
      "source": [
        "\n",
        "**Team**: Tribiotics\\\n",
        "**Team Members**: Trevor Chan, Jordan Matelsky, Jiazhen Rong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGg7_gE_KPha"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b0oYuuuoKJmD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "from torchvision.models import vgg19\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "import IPython\n",
        "import torchvision\n",
        "import cv2\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlGzNj30hKL4",
        "outputId": "2345440b-e49c-46d9-e4e2-487df5d71f58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.64.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2021.10.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (6.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7NJDH5juhMVK"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKFz8gUGhPro",
        "outputId": "bafbcb7c-ba63-48ec-a5f2-93649af3a785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: jordanmatelsky\n",
            "Your Kaggle Key: ··········\n",
            "Downloading covid19-radiography-database.zip to ./covid19-radiography-database\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 778M/778M [00:15<00:00, 54.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## download the Kaggle dataset of COVID lung X-ray \n",
        "# get your API from Kaggle, see https://www.analyticsvidhya.com/blog/2021/04/how-to-download-kaggle-datasets-using-jupyter-notebook/\n",
        "od.download(\"https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database/download\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BQShqppSuwtc"
      },
      "outputs": [],
      "source": [
        "# create an annotation file of file name + labels within the image directory\n",
        "img_dir=\"/content/covid19-radiography-database/COVID-19_Radiography_Dataset/\"\n",
        "covid_images = os.listdir(img_dir+'COVID/images')\n",
        "covid_images = [img_dir + 'COVID/images/' + img for img in covid_images]\n",
        "normal_images = os.listdir(img_dir+'Normal/images')\n",
        "normal_images = [img_dir + 'Normal/images/' + img for img in normal_images]\n",
        "pneumonia_images= os.listdir(img_dir+'Viral Pneumonia/images')\n",
        "pneumonia_images = [img_dir + 'Viral Pneumonia/images/' +img for img in pneumonia_images]\n",
        "# masking folder\n",
        "covid_mask = os.listdir(img_dir+'COVID/masks')\n",
        "covid_mask = [img_dir + 'COVID/masks/' + img for img in covid_mask]\n",
        "normal_mask = os.listdir(img_dir+'Normal/masks')\n",
        "normal_mask = [img_dir + 'Normal/masks/' + img for img in normal_mask]\n",
        "pneumonia_mask = os.listdir(img_dir+'Viral Pneumonia/masks')\n",
        "pneumonia_mask = [img_dir + 'Viral Pneumonia/masks/' +img for img in pneumonia_mask]\n",
        "\n",
        "# create label\n",
        "meta_df = pd.DataFrame(data={'data_path':covid_images+normal_images + pneumonia_images,\n",
        "                             'label':[0]*len(covid_images) + [1]*len(normal_images) + [2]*len(pneumonia_images),\n",
        "                              'masking': covid_mask+normal_mask + pneumonia_mask})\n",
        "meta_df.to_csv(img_dir+\"all_file_label.txt\",sep='\\t')\n",
        "\n",
        "# split into 80% train, 10% validation and 10% test files\n",
        "random.seed(522)\n",
        "train_idx = np.random.choice(list(range(meta_df.shape[0])),size=int(meta_df.shape[0]*0.8),replace=False)\n",
        "val_idx = np.random.choice(list(set(list(range(meta_df.shape[0]))) - set((train_idx))),size=int(meta_df.shape[0]*0.1),replace=False)\n",
        "test_idx = np.array(list(set(list(range(meta_df.shape[0]))) - set(val_idx) - set(train_idx)))\n",
        "meta_df.iloc[train_idx,:].to_csv(img_dir+\"train_split.txt\",sep='\\t')\n",
        "meta_df.iloc[val_idx,:].to_csv(img_dir+\"val_split.txt\",sep='\\t')\n",
        "meta_df.iloc[test_idx,:].to_csv(img_dir+\"test_split.txt\",sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quty3XQVKOkm"
      },
      "source": [
        "### Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "w7Uz-t8Xiv8H"
      },
      "outputs": [],
      "source": [
        "# customized data loader to save memory\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, transform=None, train_transform=None,target_transform=None,mask_transform=None,train=True,masking=False, antimasking=False):\n",
        "        self.annotations_file = pd.read_csv(annotations_file,sep='\\t',index_col=0)\n",
        "        #self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.train_transform = train_transform\n",
        "        self.train=train\n",
        "        self.target_tranform= target_transform\n",
        "        self.masking = masking \n",
        "        self.antimasking = antimasking\n",
        "        self.mask_transform = mask_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations_file)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.annotations_file.iloc[idx, 0] # image\n",
        "        mask_path = self.annotations_file.iloc[idx, 2] # masking\n",
        "        image = read_image(img_path)\n",
        "        mask = read_image(mask_path)/255\n",
        "\n",
        "        ## Change 1x299x299 images to 3x299x299 to keep consistency between datasets.\n",
        "        if image.shape[0] == 1:\n",
        "          image = torch.tile(image,(3,1,1))\n",
        "\n",
        "        # apply masking on image before any other transformation\n",
        "        if self.masking == True: \n",
        "          image = self.mask_transform(image) # resize image to be same size as mask, mask size: 3*256*256\n",
        "          image = image * mask\n",
        "        elif self.antimasking == True: \n",
        "          image = self.mask_transform(image) # resize image to be same size as mask, mask size: 3*256*256\n",
        "          image = image * -1 * (1-mask)\n",
        "\n",
        "        label = self.annotations_file.iloc[idx, 1] # image label, 0 for covid, 1 for normal, 2 for pneumonia\n",
        "\n",
        "        if self.train: # for training case, additional transformation\n",
        "            image = self.train_transform(image)\n",
        "        else:  # for validation and test case\n",
        "            image = self.transform(image)\n",
        "        if self.target_tranform != None:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3eY0Ob4lIWC"
      },
      "source": [
        "##### Without masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g3BqTMjVrvAN"
      },
      "outputs": [],
      "source": [
        "annotation_file=img_dir+\"all_file_label.txt\"\n",
        "train_file = img_dir+\"train_split.txt\"\n",
        "val_file = img_dir+\"val_split.txt\"\n",
        "test_file = img_dir+\"test_split.txt\"\n",
        "\n",
        "# Define image transformations\n",
        "# transformations - can add more transformation here, like resize for different models, etc.\n",
        "all_transforms = transforms.Compose([\n",
        "                    transforms.ToPILImage(),\n",
        "                    transforms.Resize((224, 224)), \n",
        "                    transforms.ToTensor(), \n",
        "                    # transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # imagenet images common scale factors\n",
        "                    #transforms.Normalize((0.5), (0.5)), # the covid is only 1D\n",
        "                    ])\n",
        "\n",
        "# Make image size size as masking\n",
        "mask_transform = transforms.Compose([\n",
        "                    transforms.Resize((256, 256)), \n",
        "                    ])\n",
        "# can add augmentations here for training images\n",
        "train_transforms = transforms.Compose([\n",
        "                    transforms.ToPILImage(),\n",
        "                    # transforms.RandomHorizontalFlip(),\n",
        "                    transforms.RandomRotation(degrees=5), \n",
        "                    transforms.Resize((224, 224)), \n",
        "                    transforms.ToTensor(), \n",
        "                    # transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "                    #transforms.Normalize((0.5), (0.5)), # the covid is only 1D\n",
        "                    ])\n",
        "\n",
        "full_training_data = CustomImageDataset(\n",
        "    annotations_file= train_file,\n",
        "    transform=all_transforms,\n",
        "    train_transform = train_transforms,\n",
        "    train=True,\n",
        "    masking=False,\n",
        "    antimasking=False,\n",
        "    mask_transform=mask_transform\n",
        ")\n",
        "full_val_data = CustomImageDataset(\n",
        "    annotations_file= val_file,\n",
        "    transform=all_transforms,\n",
        "    train=False,\n",
        "    masking=False,\n",
        "    antimasking=False,\n",
        "    mask_transform=mask_transform\n",
        ")\n",
        "full_test_data = CustomImageDataset(\n",
        "    annotations_file= test_file,\n",
        "    transform=all_transforms,\n",
        "    train=False,\n",
        "    masking=False,\n",
        "    antimasking=False,\n",
        "    mask_transform=mask_transform\n",
        ")\n",
        "\n",
        "\n",
        "mask_training_data = CustomImageDataset(\n",
        "    annotations_file= train_file,\n",
        "    transform=all_transforms,\n",
        "    train_transform = train_transforms,\n",
        "    train=True,\n",
        "    masking=True,\n",
        "    antimasking=False,\n",
        "    mask_transform=mask_transform\n",
        ")\n",
        "mask_val_data = CustomImageDataset(\n",
        "    annotations_file= val_file,\n",
        "    transform=all_transforms,\n",
        "    train=False,\n",
        "    masking=True,\n",
        "    antimasking=False,\n",
        "    mask_transform=mask_transform\n",
        ")\n",
        "mask_test_data = CustomImageDataset(\n",
        "    annotations_file= test_file,\n",
        "    transform=all_transforms,\n",
        "    train=False,\n",
        "    masking=True,\n",
        "    antimasking=False,\n",
        "    mask_transform=mask_transform\n",
        ")\n",
        "\n",
        "\n",
        "anti_training_data = CustomImageDataset(\n",
        "    annotations_file= train_file,\n",
        "    transform=all_transforms,\n",
        "    train_transform = train_transforms,\n",
        "    train=True,\n",
        "    masking=False,\n",
        "    antimasking=True,\n",
        "    mask_transform=mask_transform\n",
        ")\n",
        "anti_val_data = CustomImageDataset(\n",
        "    annotations_file= val_file,\n",
        "    transform=all_transforms,\n",
        "    train=False,\n",
        "    masking=False,\n",
        "    antimasking=True,\n",
        "    mask_transform=mask_transform\n",
        ")\n",
        "anti_test_data = CustomImageDataset(\n",
        "    annotations_file= test_file,\n",
        "    transform=all_transforms,\n",
        "    train=False,\n",
        "    masking=False,\n",
        "    antimasking=True,\n",
        "    mask_transform=mask_transform\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6QxaBdXwjHVU"
      },
      "outputs": [],
      "source": [
        "full_train_dataloader = DataLoader(full_training_data, batch_size=64, shuffle=True)\n",
        "full_val_dataloader = DataLoader(full_val_data, batch_size=64, shuffle=True)\n",
        "full_test_dataloader = DataLoader(full_test_data, batch_size=64, shuffle=True)\n",
        "\n",
        "mask_train_dataloader = DataLoader(mask_training_data, batch_size=64, shuffle=True)\n",
        "mask_val_dataloader = DataLoader(mask_val_data, batch_size=64, shuffle=True)\n",
        "mask_test_dataloader = DataLoader(mask_test_data, batch_size=64, shuffle=True)\n",
        "\n",
        "anti_train_dataloader = DataLoader(anti_training_data, batch_size=64, shuffle=True)\n",
        "anti_val_dataloader = DataLoader(anti_val_data, batch_size=64, shuffle=True)\n",
        "anti_test_dataloader = DataLoader(anti_test_data, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('COVID', 'Normal', 'Pneumonia')\n",
        "def render_classes():\n",
        "    render = 0\n",
        "    for (imgs, labels) in full_train_dataloader:\n",
        "        for img, lab in zip(imgs, labels):\n",
        "            if render == lab:\n",
        "                plt.title(classes[render])\n",
        "                plt.imshow(img[0,:,:], cmap='Greys_r')\n",
        "                plt.show()\n",
        "                render += 1\n",
        "            if render == 3:\n",
        "                return\n",
        "render_classes()"
      ],
      "metadata": {
        "id": "87dDAFBdBip2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('COVID', 'Normal', 'Pneumonia')\n"
      ],
      "metadata": {
        "id": "ZtlsUTFiC4OP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_df.groupby(\"label\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "sXYjFrN-zibJ",
        "outputId": "d27f568c-938b-4306-c632-965927e1ec94"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       data_path  masking\n",
              "label                    \n",
              "0           3616     3616\n",
              "1          10192    10192\n",
              "2           1345     1345"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dec32eed-87ae-4f0e-bdaa-10c2b53b553f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_path</th>\n",
              "      <th>masking</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3616</td>\n",
              "      <td>3616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10192</td>\n",
              "      <td>10192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1345</td>\n",
              "      <td>1345</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dec32eed-87ae-4f0e-bdaa-10c2b53b553f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dec32eed-87ae-4f0e-bdaa-10c2b53b553f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dec32eed-87ae-4f0e-bdaa-10c2b53b553f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RiHafn4Mz4mP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CIS522-DL-Tribiotics-Dataset-Exploration",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}